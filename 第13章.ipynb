{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               x_t              h_t\n",
    "                │                │\n",
    "                ▼                ▼\n",
    "          ╔════════╗      ╔════════╗      ╔════════╗\n",
    "          ║ Input  ║      ║ Forget ║      ║ Output ║ \n",
    "          ║  Gate  ║◀─────║  Gate  ║◀─────║  Gate  ║\n",
    "          ╚════════╝      ╚════════╝      ╚════════╝\n",
    "                │                │                │\n",
    "                ▼                ▼                ▼\n",
    "          ╔════════╗      ╔════════╗      ╔════════╗\n",
    "          ║        ║      ║ Memory ║      ║        ║ \n",
    "          ║   C_t  ║◀─────║  Cell  ║◀─────║   C_t  ║  \n",
    "          ║        ║      ║        ║      ║        ║ \n",
    "          ╚════════╝      ╚════════╝      ╚════════╝\n",
    "                │                │                │\n",
    "                ▼                ▼                ▼\n",
    "              output           state            input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设我们有一个包含4个不同单词的词汇表\n",
    "vocab = {'apple': 0, 'banana': 1, 'orange': 2, 'pear': 3}\n",
    "\n",
    "# 将句子表示为单词列表\n",
    "sentence = ['apple', 'banana', 'orange']\n",
    "\n",
    "# 创建一个长度为词汇表大小的零向量\n",
    "vector = np.zeros(len(vocab))\n",
    "\n",
    "# 对于句子中的每个单词，将对应的向量元素设置为1\n",
    "for word in sentence:\n",
    "    index = vocab[word]\n",
    "    vector[index] = 1\n",
    "    \n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 创建一个字符串列表作为示例数据\n",
    "text_data = np.reshape([\"中国\", \"美国\", \"英国\", \"德国\", \"日本\"], (-1,1))\n",
    "\n",
    "# 创建OneHotEncoder对象\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# 使用fit_transform方法将字符串转换为独热编码向量\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(text_data)\n",
    "\n",
    "# 输出独热编码向量\n",
    "print(one_hot_encoded.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['中国'],\n",
       "       ['美国'],\n",
       "       ['英国'],\n",
       "       ['德国'],\n",
       "       ['日本']], dtype='<U2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 构建文本数据集\n",
    "corpus = ['This is the first document.', 'This document is the second document.', 'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "# 定义词袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 对文本进行向量化表示\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 输出向量化结果\n",
    "print(X.toarray())\n",
    "\n",
    "# 输出特征名\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 假设你有一个文本列表，每个字符串表示一篇文章或一个句子\n",
    "text_data = [\"This is a sentence.\", \"This is another sentence.\", \"This is a third sentence.\"]\n",
    "\n",
    "# 创建TF-IDF向量器\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# 使用fit_transform方法将文本数据转换成TF-IDF向量\n",
    "tfidf_vectors = tfidf.fit_transform(text_data)\n",
    "\n",
    "# 查看TF-IDF矩阵的形状\n",
    "print(tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 11 stored elements and shape (3, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 4)\t0.5773502691896258\n",
      "  (0, 1)\t0.5773502691896258\n",
      "  (0, 2)\t0.5773502691896258\n",
      "  (1, 4)\t0.4128585720620119\n",
      "  (1, 1)\t0.4128585720620119\n",
      "  (1, 2)\t0.4128585720620119\n",
      "  (1, 0)\t0.6990303272568005\n",
      "  (2, 4)\t0.4128585720620119\n",
      "  (2, 1)\t0.4128585720620119\n",
      "  (2, 2)\t0.4128585720620119\n",
      "  (2, 3)\t0.6990303272568005\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['another', 'is', 'sentence', 'third', 'this'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面是剧本情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ('train_dataset_v2.tsv')\n",
    "script_ids = []\n",
    "scene_nums = []\n",
    "sentence_nums = []\n",
    "ids = []\n",
    "contents = []\n",
    "characters = []\n",
    "emotions = []\n",
    "index = 0\n",
    "with open(file_path,'r',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if index > 0:\n",
    "            item = line.replace('\\n','').split('\\t')\n",
    "            id,content,character,emotion = item[0],item[1],item[2],item[3]\n",
    "            script_id,scene_num,sentence_num = id.split('_')[0],id.split('_')[1],id.split('_')[3]\n",
    "            script_ids.append(script_id)\n",
    "            scene_nums.append(scene_num)\n",
    "            sentence_nums.append(sentence_num)\n",
    "            ids.append(id)\n",
    "            contents.append(content)\n",
    "            characters.append(character)\n",
    "            emotions.append(emotion)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>contents</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171_0001_A_1</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171_0001_A_2</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171_0001_A_3</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171_0001_A_4</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1171_0001_A_5</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ids                                           contents  \\\n",
       "0  1171_0001_A_1          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "1  1171_0001_A_2          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "2  1171_0001_A_3                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "3  1171_0001_A_4                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "4  1171_0001_A_5  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...   \n",
       "\n",
       "      emotions  \n",
       "0  0,0,0,0,0,0  \n",
       "1  0,0,0,0,0,0  \n",
       "2  0,0,0,0,0,0  \n",
       "3  0,0,0,0,0,0  \n",
       "4  0,0,0,0,0,0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=['ids','contents', 'emotions'])\n",
    "data['ids'] = pd.Series(ids)\n",
    "data['contents'] = pd.Series(contents)\n",
    "data['emotions'] = pd.Series(emotions)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>contents</th>\n",
       "      <th>emotions</th>\n",
       "      <th>love</th>\n",
       "      <th>happy</th>\n",
       "      <th>shock</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171_0001_A_1</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171_0001_A_2</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171_0001_A_3</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171_0001_A_4</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1171_0001_A_5</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ids                                           contents  \\\n",
       "0  1171_0001_A_1          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "1  1171_0001_A_2          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "2  1171_0001_A_3                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "3  1171_0001_A_4                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "4  1171_0001_A_5  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...   \n",
       "\n",
       "      emotions love happy shock anger fear sad  \n",
       "0  0,0,0,0,0,0    0     0     0     0    0   0  \n",
       "1  0,0,0,0,0,0    0     0     0     0    0   0  \n",
       "2  0,0,0,0,0,0    0     0     0     0    0   0  \n",
       "3  0,0,0,0,0,0    0     0     0     0    0   0  \n",
       "4  0,0,0,0,0,0    0     0     0     0    0   0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emo = data['emotions'].str.split(',', expand=True)\n",
    "\n",
    "df_emo.rename(columns={0:'love', 1:'happy', 2:'shock', 3:'anger', 4:'fear', 5:'sad'}, inplace=True)\n",
    "\n",
    "data = pd.concat([data, df_emo], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ids         0\n",
       "contents    0\n",
       "emotions    0\n",
       "love        0\n",
       "happy       0\n",
       "shock       0\n",
       "anger       0\n",
       "fear        0\n",
       "sad         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36782"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ids', 'contents', 'emotions', 'love', 'happy', 'shock', 'anger',\n",
       "       'fear', 'sad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>contents</th>\n",
       "      <th>emotions</th>\n",
       "      <th>love</th>\n",
       "      <th>happy</th>\n",
       "      <th>shock</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sad</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171_0001_A_1</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>天空 下 着 暴雨 ， o2 正在 给 c1 穿 雨衣 ， 他 自己 却 只 穿着 单薄 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171_0001_A_2</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>天空 下 着 暴雨 ， o2 正在 给 c1 穿 雨衣 ， 他 自己 却 只 穿着 单薄 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171_0001_A_3</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>o2 一 手拿着 一个 行李 ， 一路 小跑 着 把 c1 带到 了 文工团 门口 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171_0001_A_4</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>o2 一 手拿着 一个 行李 ， 一路 小跑 着 把 c1 带到 了 文工团 门口 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1171_0001_A_5</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>o2 停下来 接过 c1 手里 的 行李 ： 你 妈妈 交待 我 了 ， 等 领 了 军装 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ids                                           contents  \\\n",
       "0  1171_0001_A_1          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "1  1171_0001_A_2          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。   \n",
       "2  1171_0001_A_3                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "3  1171_0001_A_4                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。   \n",
       "4  1171_0001_A_5  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...   \n",
       "\n",
       "      emotions love happy shock anger fear sad  \\\n",
       "0  0,0,0,0,0,0    0     0     0     0    0   0   \n",
       "1  0,0,0,0,0,0    0     0     0     0    0   0   \n",
       "2  0,0,0,0,0,0    0     0     0     0    0   0   \n",
       "3  0,0,0,0,0,0    0     0     0     0    0   0   \n",
       "4  0,0,0,0,0,0    0     0     0     0    0   0   \n",
       "\n",
       "                                                text  \n",
       "0  天空 下 着 暴雨 ， o2 正在 给 c1 穿 雨衣 ， 他 自己 却 只 穿着 单薄 的...  \n",
       "1  天空 下 着 暴雨 ， o2 正在 给 c1 穿 雨衣 ， 他 自己 却 只 穿着 单薄 的...  \n",
       "2        o2 一 手拿着 一个 行李 ， 一路 小跑 着 把 c1 带到 了 文工团 门口 。  \n",
       "3        o2 一 手拿着 一个 行李 ， 一路 小跑 着 把 c1 带到 了 文工团 门口 。  \n",
       "4  o2 停下来 接过 c1 手里 的 行李 ： 你 妈妈 交待 我 了 ， 等 领 了 军装 ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "# 定义一个分词函数\n",
    "def tokenize(text):\n",
    "    return ' '.join(jieba.cut(text))\n",
    "\n",
    "# 对剧本内容列应用分词函数\n",
    "data['text'] = data['contents'].apply(tokenize)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 用于数据处理和分析\n",
    "import numpy as np  # 用于数值计算\n",
    "from sklearn.model_selection import train_test_split  # 用于划分训练集和测试集\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # 用于文本分词\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # 用于填充序列\n",
    "from tensorflow.keras.models import Sequential  # 用于构建顺序模型\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding  # 用于定义模型层\n",
    "\n",
    "# 将文本列转化为序列\n",
    "tokenizer = Tokenizer(num_words=5000)  # 保留最常见的5000个单词\n",
    "tokenizer.fit_on_texts(data['text'])  # 使用文本数据拟合分词器\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])  # 将文本转化为整数序列\n",
    "\n",
    "# 对序列进行填充\n",
    "max_len = max(len(s) for s in sequences)  # 计算最长序列的长度\n",
    "seq = pad_sequences(sequences, maxlen=max_len)  # 将所有序列填充到相同长度\n",
    "\n",
    "# 将标签列转化为二进制矩阵\n",
    "labels = np.asarray(data[['love', 'happy', 'shock', 'anger', 'fear', 'sad']].astype('int64'))\n",
    "num_labels = labels.shape[1]  # 标签的数量\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(seq, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 88ms/step - accuracy: 0.1332 - loss: 0.3968 - val_accuracy: 0.1707 - val_loss: 0.3379\n",
      "Epoch 2/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 89ms/step - accuracy: 0.1958 - loss: 0.2923 - val_accuracy: 0.2039 - val_loss: 0.2960\n",
      "Epoch 3/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 89ms/step - accuracy: 0.2425 - loss: 0.1869 - val_accuracy: 0.2145 - val_loss: 0.2520\n",
      "Epoch 4/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 90ms/step - accuracy: 0.2737 - loss: 0.0249 - val_accuracy: 0.2130 - val_loss: 0.2240\n",
      "Epoch 5/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 89ms/step - accuracy: 0.2771 - loss: -0.1483 - val_accuracy: 0.2104 - val_loss: 0.1824\n",
      "Epoch 6/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 91ms/step - accuracy: 0.2871 - loss: -0.4384 - val_accuracy: 0.2236 - val_loss: 0.2703\n",
      "Epoch 7/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 100ms/step - accuracy: 0.2957 - loss: -0.6201 - val_accuracy: 0.2318 - val_loss: 0.1647\n",
      "Epoch 8/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 85ms/step - accuracy: 0.3106 - loss: -1.1385 - val_accuracy: 0.2005 - val_loss: 0.3135\n",
      "Epoch 9/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 99ms/step - accuracy: 0.3031 - loss: -1.5998 - val_accuracy: 0.2235 - val_loss: 0.1780\n",
      "Epoch 10/10\n",
      "\u001b[1m920/920\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 157ms/step - accuracy: 0.3101 - loss: -1.9356 - val_accuracy: 0.2251 - val_loss: 0.2822\n",
      "Accuracy: 22.51%\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = Sequential()  # 创建一个顺序模型\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_len))  # 嵌入层\n",
    "model.add(LSTM(units=64))  # LSTM层\n",
    "model.add(Dense(units=num_labels, activation='sigmoid'))  # 输出层，使用sigmoid激活函数处理多标签分类\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam',  # 使用Adam优化器\n",
    "              loss='binary_crossentropy',  # 使用二分类交叉熵作为损失函数，适用于多标签分类\n",
    "              metrics=['accuracy'])  # 监测准确率作为评估指标\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, y_train,  # 训练数据和标签\n",
    "                    epochs=10,  # 训练10轮\n",
    "                    batch_size=32,  # 每个批次处理32个样本\n",
    "                    validation_data=(X_test, y_test))  # 使用测试集作为验证集\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)  # 在测试集上评估模型\n",
    "print('Accuracy: %.2f%%' % (accuracy * 100))  # 打印测试集上的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
